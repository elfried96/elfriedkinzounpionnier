# ğŸ”„ Pipeline de classification des maladies du manioc

Ce document dÃ©taille le pipeline complet mis en place pour la classification automatique des maladies du manioc Ã  partir d'images, en utilisant PyTorch.

---

## 1. ğŸ“‚ Chargement et prÃ©paration des donnÃ©es

- **Source des donnÃ©es** : Images collectÃ©es sur le terrain, organisÃ©es par classe dans le rÃ©pertoire `data/raw/`.
- **Chargement** : Utilisation de `torchvision.datasets.ImageFolder` pour structurer les donnÃ©es.
- **Transformations appliquÃ©es** :
  - Redimensionnement des images Ã  une taille uniforme (par exemple, 224x224 pixels).
  - Normalisation des canaux RGB selon les moyennes et Ã©carts-types d'ImageNet.
  - Augmentations de donnÃ©es (rotations, flips horizontaux) pour amÃ©liorer la robustesse du modÃ¨le.

---

## 2. ğŸ§ª SÃ©paration du jeu de donnÃ©es

- **RÃ©partition** :
  - EntraÃ®nement : 70%
  - Validation : 15%
  - Test : 15%
- **MÃ©thode** : Utilisation de `torch.utils.data.random_split` avec une graine fixe (`torch.Generator().manual_seed(42)`) pour assurer la reproductibilitÃ©.

---

## 3. âš–ï¸ Gestion du dÃ©sÃ©quilibre des classes

- **Analyse** : Comptage des occurrences de chaque classe Ã  l'aide de `collections.Counter`.
- **Techniques mises en Å“uvre** :
  - **PondÃ©ration de la fonction de perte** : Calcul des poids inverses des frÃ©quences des classes pour `torch.nn.CrossEntropyLoss`.
  - **Sampler pondÃ©rÃ©** : Optionnellement, utilisation de `torch.utils.data.WeightedRandomSampler` pour Ã©quilibrer les classes lors de l'entraÃ®nement.

---

## 4. ğŸ§  ModÃ©lisation

- **Architecture personnalisÃ©e** : Convolutional Neural Network (CNN) dÃ©fini dans `models/classifier.py`.
- **ModÃ¨les prÃ©-entraÃ®nÃ©s** : IntÃ©gration de modÃ¨les tels que `ResNet18` via `torchvision.models` pour le transfert d'apprentissage.
- **Fonction de perte** : `torch.nn.CrossEntropyLoss` avec ou sans pondÃ©ration.
- **Optimiseur** : `torch.optim.Adam` avec un taux d'apprentissage initial de 1e-4.

---

## 5. ğŸ‹ï¸ EntraÃ®nement

- **Boucle d'entraÃ®nement** : ImplÃ©mentÃ©e dans `training.py`, avec suivi de la perte et de la prÃ©cision.
- **Sauvegarde du modÃ¨le** : Enregistrement des poids du modÃ¨le aprÃ¨s chaque Ã©poque si la performance s'amÃ©liore.
- **Visualisation** : Courbes de perte et de prÃ©cision gÃ©nÃ©rÃ©es Ã  l'aide de `matplotlib`.

---

## 6. ğŸ“Š Ã‰valuation

- **MÃ©triques** :
  - PrÃ©cision globale.
  - Matrice de confusion.
  - Rapport de classification (prÃ©cision, rappel, F1-score).
- **ExplicabilitÃ©** : Utilisation de `torchcam` pour gÃ©nÃ©rer des cartes de chaleur (Grad-CAM) illustrant les zones d'attention du modÃ¨le.

---

## 7. ğŸ“ Organisation des fichiers

```plaintext
data/
â”œâ”€â”€ raw/                # Images originales
â”œâ”€â”€ processed/          # DonnÃ©es aprÃ¨s sÃ©paration
models/
â”œâ”€â”€ classifier.py       # DÃ©finition du modÃ¨le
â”œâ”€â”€ utils.py            # Fonctions utilitaires
notebooks/
â”œâ”€â”€ exploration.ipynb   # Analyse exploratoire
â”œâ”€â”€ training.ipynb      # EntraÃ®nement du modÃ¨le
scripts/
â”œâ”€â”€ split_data.py       # Script de sÃ©paration des donnÃ©es
â”œâ”€â”€ train_model.py      # Script d'entraÃ®nement

```
