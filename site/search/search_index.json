{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Accueil","text":""},{"location":"#projet-classification-des-maladies-du-manioc","title":"Projet : Classification des maladies du manioc","text":""},{"location":"#presentation-generale","title":"Pr\u00e9sentation g\u00e9n\u00e9rale","text":"<p>Ce projet vise \u00e0 d\u00e9velopper un pipeline complet de classification multiclasse pour identifier automatiquement les maladies du manioc \u00e0 partir d\u2019images : - Passage d\u2019une approche d\u2019annotation via Azure AI \u00e0 un mod\u00e8le PyTorch entra\u00een\u00e9 sur vos images. - Structure reproduisible, tests, notebooks d\u2019exploration et site de documentation auto-d\u00e9ploy\u00e9.</p>"},{"location":"#contexte","title":"Contexte","text":"<p>Le manioc est une culture critique en Afrique de l\u2019Ouest, soumise \u00e0 des maladies comme : - Cassava Mosaic Disease (CMD) - Cassava Brown Streak Disease (CBSD) - Cassava Bacterial Blight (CBB) - Cassava Green Mottle - Plantes saines </p> <p>L\u2019automatisation de la d\u00e9tection et de la classification acc\u00e9l\u00e8re la surveillance des cultures et la cr\u00e9ation de datasets annot\u00e9s de haute qualit\u00e9.</p>"},{"location":"#objectifs","title":"Objectifs","text":"<ul> <li>Principal : Classifier 5 \u00e9tats/maladies du manioc via un mod\u00e8le CNN PyTorch.  </li> <li>Sp\u00e9cifiques :  </li> <li>Pr\u00e9traiter et organiser le dataset (raw \u2192 processed).  </li> <li>G\u00e9rer l\u2019\u00e9quilibre des classes (pond\u00e9ration de la perte &amp; sampler pond\u00e9r\u00e9).  </li> <li>Impl\u00e9menter et comparer un CNN personnalis\u00e9 et un mod\u00e8le pr\u00e9-entra\u00een\u00e9.  </li> <li>Entra\u00eener, \u00e9valuer (courbes, matrice de confusion) et explicabiliser (Grad-CAM).  </li> <li>Documenter chaque \u00e9tape et d\u00e9ployer via MkDocs + GitHub Pages.</li> </ul>"},{"location":"#technologies","title":"Technologies","text":"Outil / Langage Usage principal Python &amp; PyTorch Mod\u00e9lisation, entra\u00eenement, \u00e9valuation torchvision <code>ImageFolder</code>, transforms, mod\u00e8les pr\u00e9-entra\u00een\u00e9s Matplotlib &amp; Seaborn Visualisation (courbes, matrices de confusion) Captum / TorchCAM Explicabilit\u00e9 (saliency maps, Grad-CAM) Jupyter Notebooks Exploration, d\u00e9mo interactive MkDocs + Material G\u00e9n\u00e9ration du site de documentation GitHub Actions CI pour tests et d\u00e9ploiement documentaire"},{"location":"#structure-du-depot","title":"Structure du d\u00e9p\u00f4t","text":"<pre><code>elfriedkinzounpionniers/\n\u251c\u2500\u2500 ci/                    # Environnements conda, CI\n\u251c\u2500\u2500 data/                  # Donn\u00e9es brutes et processing\n\u2502   \u251c\u2500\u2500 raw/               # Images par classe\n\u2502   \u251c\u2500\u2500 processed/         # train/val/test organis\u00e9s\n\u2502   \u2514\u2500\u2500 metadata.csv       # M\u00e9tadonn\u00e9es du dataset\n\u251c\u2500\u2500 docs/                  # Documentation MkDocs\n\u2502   \u251c\u2500\u2500 index.md           # Cette page\n\u2502   \u251c\u2500\u2500 data.md            # Dashboard dataset &amp; gallery\n\u2502   \u251c\u2500\u2500 pipeline.md        # Pipeline d\u00e9taill\u00e9 (pr\u00e9traitement \u2192 \u00e9valuation)\n\u2502   \u251c\u2500\u2500 model.md           # Architectures et choix de mod\u00e8le\n\u2502   \u251c\u2500\u2500 training.md        # Entra\u00eenement &amp; hyperparam\u00e8tres\n\u2502   \u2514\u2500\u2500 evaluation.md      # R\u00e9sultats, matrices, explicabilit\u00e9\n\u251c\u2500\u2500 models/                # D\u00e9finitions des architectures PyTorch\n\u2502   \u251c\u2500\u2500 classifier.py\n\u2502   \u2514\u2500\u2500 utils.py\n\u251c\u2500\u2500 notebooks/             # Notebooks d\u2019exploration &amp; d\u00e9mo\n\u251c\u2500\u2500 scripts/               # Outils (split, preprocess, inference)\n\u251c\u2500\u2500 training.py            # Fonctions train/predict/save/load\n\u251c\u2500\u2500 environment.yml        # D\u00e9pendances\n\u251c\u2500\u2500 README.md              # Lien vers docs/index.md\n\u2514\u2500\u2500 tests/                 # Tests unitaires\n</code></pre>"},{"location":"apk/","title":"Cassava Ol\u00f9\u1e63\u1ecd\u0301 - Diagnostic Intelligent des Maladies du Manioc","text":""},{"location":"apk/#a-propos-du-projet","title":"\ud83c\udf3f \u00c0 Propos du Projet","text":"<p>Cassava Ol\u00f9\u1e63\u1ecd\u0301 est une application web innovante d\u00e9di\u00e9e \u00e0 la classification automatique et \u00e0 la description des maladies du manioc \u00e0 l'aide de l'intelligence artificielle.</p>"},{"location":"apk/#objectif-principal","title":"\ud83c\udfaf Objectif Principal","text":"<p>Aider les agriculteurs et les chercheurs \u00e0 identifier rapidement et pr\u00e9cis\u00e9ment les maladies affectant les plants de manioc, en utilisant des technologies d'intelligence artificielle avanc\u00e9es.</p>"},{"location":"apk/#technologies-utilisees","title":"\ud83d\udee0 Technologies Utilis\u00e9es","text":""},{"location":"apk/#frontend","title":"Frontend","text":"<ul> <li>React 18</li> <li>TypeScript</li> <li>Vite</li> <li>Tailwind CSS</li> <li>shadcn/ui</li> <li>React Query</li> <li>React Router</li> <li>Framer Motion</li> </ul>"},{"location":"apk/#backend-futur-developpement","title":"Backend (Futur D\u00e9veloppement)","text":"<ul> <li>FastAPI</li> <li>SQLAlchemy</li> <li>Pydantic</li> <li>JWT Authentication</li> <li>SQLite (d\u00e9veloppement)</li> <li>PostgreSQL (production)</li> </ul>"},{"location":"apk/#fonctionnalites","title":"\ud83d\ude80 Fonctionnalit\u00e9s","text":"<ul> <li>\ud83d\udcf8 T\u00e9l\u00e9chargement d'images de feuilles de manioc</li> <li>\ud83d\udd0d Classification automatique des maladies</li> <li>\ud83d\udcdd G\u00e9n\u00e9ration de descriptions d\u00e9taill\u00e9es</li> <li>\ud83d\udc65 Gestion des utilisateurs et des droits</li> </ul>"},{"location":"apk/#prerequis","title":"\ud83d\udce6 Pr\u00e9requis","text":"<ul> <li>Node.js (v18+)</li> <li>npm ou yarn</li> <li>Python 3.9+ (pour le backend)</li> </ul>"},{"location":"apk/#installation","title":"\ud83d\udd27 Installation","text":""},{"location":"apk/#frontend_1","title":"Frontend","text":"<pre><code># Cloner le repository\ngit clone https://github.com/elfried96/cassava-vision-guard.git\n\n# Naviguer dans le dossier du projet\ncd cassava-olu\u1e63\u1ecd\u0301\n\n# Installer les d\u00e9pendances\nnpm install\n\n# Lancer le serveur de d\u00e9veloppement\nnpm run dev\n</code></pre>"},{"location":"apk/#backend-todo","title":"Backend (TODO)","text":"<pre><code># Installation des d\u00e9pendances Python\npip install fastapi uvicorn sqlalchemy pydantic python-jose[cryptography]\n\n# Lancer le serveur Backend\nuvicorn main:app --reload\n</code></pre>"},{"location":"apk/#structure-du-projet","title":"\ud83d\uddc2 Structure du Projet","text":"<pre><code>cassava-olu\u1e63\u1ecd\u0301/\n\u2502\n\u251c\u2500\u2500 frontend/\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 components/\n\u2502   \u2502   \u251c\u2500\u2500 pages/\n\u2502   \u2502   \u251c\u2500\u2500 hooks/\n\u2502   \u2502   \u2514\u2500\u2500 utils/\n\u2502\n\u2514\u2500\u2500 backend/\n    \u251c\u2500\u2500 main.py\n    \u251c\u2500\u2500 models.py\n    \u251c\u2500\u2500 schemas.py\n    \u2514\u2500\u2500 ml_model/\n</code></pre>"},{"location":"apk/#licence","title":"\ud83d\udcc4 Licence","text":"<p>Distribu\u00e9 sous licence MIT.</p>"},{"location":"apk/#contact","title":"\ud83d\udcde Contact","text":"<p>Votre Nom - ekfriedkinzoun@gmail.com</p> <p>Projet Link: https://github.com/elfried96/cassava-vision-guard.git</p>"},{"location":"conclusion/","title":"Conclusion","text":"<p>```markdown</p>"},{"location":"conclusion/#conclusion-et-perspectives","title":"\u2705 Conclusion et perspectives","text":"<p>Ce document r\u00e9sume les r\u00e9alisations du projet de classification des maladies du manioc et propose des axes d'am\u00e9lioration pour les travaux futurs.</p>"},{"location":"conclusion/#resume-des-realisations","title":"\ud83c\udfaf R\u00e9sum\u00e9 des r\u00e9alisations","text":"<ul> <li>Pipeline complet : Mise en place d'un pipeline de classification d'images, de la pr\u00e9paration des donn\u00e9es \u00e0 l'\u00e9valuation du mod\u00e8le.</li> <li>Gestion du d\u00e9s\u00e9quilibre : Application de techniques pour att\u00e9nuer l'impact du d\u00e9s\u00e9quilibre des classes.</li> <li>Mod\u00e9lisation efficace : Utilisation de CNN personnalis\u00e9s et de mod\u00e8les pr\u00e9-entra\u00een\u00e9s pour am\u00e9liorer la performance.</li> <li>Explicabilit\u00e9 : Int\u00e9gration de m\u00e9thodes pour interpr\u00e9ter les d\u00e9cisions du mod\u00e8le.</li> </ul>"},{"location":"conclusion/#resultats-obtenus","title":"\ud83d\udcc8 R\u00e9sultats obtenus","text":"<ul> <li>Pr\u00e9cision globale : [Ins\u00e9rer la valeur obtenue].</li> <li>Classes les mieux reconnues : [Lister les classes avec les meilleures performances].</li> <li>Am\u00e9liorations observ\u00e9es : R\u00e9duction de l'erreur sur les classes minoritaires gr\u00e2ce \u00e0 la pond\u00e9ration de la perte.</li> </ul>"},{"location":"conclusion/#perspectives-damelioration","title":"\ud83d\ude80 Perspectives d'am\u00e9lioration","text":"<ul> <li>Augmentation des donn\u00e9es : Collecte de nouvelles images pour enrichir le dataset.</li> <li>Optimisation des hyperparam\u00e8tres : Exploration de diff\u00e9rentes configurations pour am\u00e9liorer la performance.</li> <li>D\u00e9ploiement : Mise en place d'une API ou d'une interface utilisateur pour faciliter l'utilisation du mod\u00e8le.</li> </ul>"},{"location":"conclusion/#ressources-supplementaires","title":"\ud83d\udcda Ressources suppl\u00e9mentaires","text":"<ul> <li>Documentation PyTorch</li> <li>Tutoriels PyTorch</li> <li>TorchCAM</li> </ul>"},{"location":"contact/","title":"Contact","text":""},{"location":"contact/#nous-contacter","title":"Nous contacter","text":"<p>Si vous avez des questions ou souhaitez entrer en contact avec nous, veuillez utiliser les informations ci-dessous :</p>"},{"location":"contact/#adresse","title":"Adresse","text":"<p>Abomey Calavi</p>"},{"location":"contact/#telephone","title":"T\u00e9l\u00e9phone","text":"<p>+229 0196848729</p>"},{"location":"contact/#email","title":"Email","text":"<p>ekfriedkinzoun@gmail.com</p>"},{"location":"contact/#reseaux-sociaux","title":"R\u00e9seaux sociaux","text":"<ul> <li> <p>Facebook</p> </li> <li> <p>LinkedIn</p> </li> </ul> <p>Nous sommes impatients de vous entendre !</p>"},{"location":"data/","title":"data","text":""},{"location":"data/#apercu-du-dataset","title":"\ud83e\uddec Aper\u00e7u du Dataset","text":"<p>Le dataset est constitu\u00e9 de X images de feuilles de manioc class\u00e9es en 8 cat\u00e9gories de sant\u00e9/maladies. Chaque image a \u00e9t\u00e9 annot\u00e9e manuellement et pr\u00e9trait\u00e9e pour entra\u00eener un mod\u00e8le de classification.</p> <ul> <li>\ud83d\udce6 Total d'images : X</li> <li>\ud83d\udcc2 Classes : 5</li> <li>\ud83d\uddbc\ufe0f Taille normalis\u00e9e : 224x224 pixels</li> </ul>"},{"location":"data/#repartition-des-classes-pour-le-train","title":"\ud83d\udcca R\u00e9partition des classes Pour le train","text":""},{"location":"data/#tableau-resume","title":"Tableau r\u00e9sum\u00e9","text":"Classe Nombre d'images Description courte Exemple Cassava Mosaic 13.2k Feuilles avec motifs marbr\u00e9s irr\u00e9guliers Cassava Bacterial Blight 1087 Feuilles perfor\u00e9es avec n\u00e9crose humide Cassava Healthy 2577 Feuilles saines, vertes homog\u00e8nes Cassava Brown Streak Disease 2189 Taches brunes le long des nervures Cassava Green Mottle 2338 Feuilles saines, vertes homog\u00e8nes <p>Pour plus d'informtion veiller consulter  Kaggle</p> <p>mkdocs serve</p>"},{"location":"installation/","title":"Guide d'Installation","text":"<p>Cette section d\u00e9crit en d\u00e9tail comment installer et configurer l'environnement de d\u00e9veloppement n\u00e9cessaire pour ex\u00e9cuter le pipeline d'annotation automatique des images de maladies du manioc. Le but est d'assurer une reproduction facile et fiable des r\u00e9sultats, conform\u00e9ment aux standards d'un projet scientifique.</p>"},{"location":"installation/#prerequis","title":"Pr\u00e9requis","text":"<p>Avant de commencer, assurez-vous d'avoir :</p> <ul> <li>Git install\u00e9 pour cloner le d\u00e9p\u00f4t.</li> <li>Python 3.8 (ou version sup\u00e9rieure) install\u00e9 sur votre machine.</li> <li>Conda (optionnel, mais recommand\u00e9) pour g\u00e9rer les environnements virtuels.</li> <li>Acc\u00e8s \u00e0 une machine (ou VM Azure) avec une configuration minimale requise (8GB de RAM, 4 CPU).</li> <li>Cl\u00e9s d'API Azure pour acc\u00e9der aux services Azure Computer Vision / Custom Vision (voir Configuration d'Azure AI).</li> </ul>"},{"location":"installation/#1-cloner-le-depot","title":"1. Cloner le D\u00e9p\u00f4t","text":"<p>Ouvrez un terminal et ex\u00e9cutez la commande suivante pour cloner le d\u00e9p\u00f4t GitHub du projet :</p> <pre><code>git clone https://github.com/elfried96/elfriedkinzounpionniers.git\ncd elfriedkinzounpionniers\n</code></pre>"},{"location":"methodologie/","title":"M\u00e9thodologie du Pipeline d\u2019Annotation Automatique","text":"<p>Ce document d\u00e9crit de mani\u00e8re exhaustive le pipeline utilis\u00e9 pour l\u2019annotation automatique des images de maladies du manioc. Chaque \u00e9tape a \u00e9t\u00e9 con\u00e7ue pour garantir la reproductibilit\u00e9, la pr\u00e9cision et la robustesse de l\u2019annotation, en tirant parti des API Azure.</p>"},{"location":"methodologie/#vue-densemble-du-pipeline","title":"Vue d\u2019ensemble du Pipeline","text":"<p>Le pipeline d\u2019annotation automatique se d\u00e9cline en 5 \u00e9tapes principales :</p> <ol> <li>Collecte et Pr\u00e9traitement des Donn\u00e9es</li> <li>Configuration et Utilisation des API Azure</li> <li>Annotation Automatique</li> <li>Post-traitement et Agr\u00e9gation des R\u00e9sultats</li> <li>\u00c9valuation des Performances et Validation</li> </ol> <p>Pour mieux visualiser l\u2019architecture g\u00e9n\u00e9rale, voici un sch\u00e9ma simplifi\u00e9 :</p> <p>```mermaid flowchart TD     A[Collecte des Images] --&gt; B[Pr\u00e9traitement des Images]     B --&gt; C[Interrogation des API Azure]     C --&gt; D[Post-traitement]     D --&gt; E[\u00c9valuation et Validation]</p>"},{"location":"pipeline/01_preparation/","title":"\ud83d\udd04 Pipeline de classification des maladies du manioc","text":"<p>Ce document d\u00e9taille le pipeline complet mis en place pour la classification automatique des maladies du manioc \u00e0 partir d'images, en utilisant PyTorch.</p>"},{"location":"pipeline/01_preparation/#1-chargement-et-preparation-des-donnees","title":"1. \ud83d\udcc2 Chargement et pr\u00e9paration des donn\u00e9es","text":"<ul> <li>Source des donn\u00e9es : Images collect\u00e9es sur le terrain, organis\u00e9es par classe dans le r\u00e9pertoire <code>data/raw/</code>.</li> <li>Chargement : Utilisation de <code>torchvision.datasets.ImageFolder</code> pour structurer les donn\u00e9es.</li> <li>Transformations appliqu\u00e9es :</li> <li>Redimensionnement des images \u00e0 une taille uniforme (par exemple, 224x224 pixels).</li> <li>Normalisation des canaux RGB selon les moyennes et \u00e9carts-types d'ImageNet.</li> <li>Augmentations de donn\u00e9es (rotations, flips horizontaux) pour am\u00e9liorer la robustesse du mod\u00e8le.</li> </ul>"},{"location":"pipeline/01_preparation/#2-separation-du-jeu-de-donnees","title":"2. \ud83e\uddea S\u00e9paration du jeu de donn\u00e9es","text":"<ul> <li>R\u00e9partition :</li> <li>Entra\u00eenement : 70%</li> <li>Validation : 15%</li> <li>Test : 15%</li> <li>M\u00e9thode : Utilisation de <code>torch.utils.data.random_split</code> avec une graine fixe (<code>torch.Generator().manual_seed(42)</code>) pour assurer la reproductibilit\u00e9.</li> </ul>"},{"location":"pipeline/01_preparation/#3-gestion-du-desequilibre-des-classes","title":"3. \u2696\ufe0f Gestion du d\u00e9s\u00e9quilibre des classes","text":"<ul> <li>Analyse : Comptage des occurrences de chaque classe \u00e0 l'aide de <code>collections.Counter</code>.</li> <li>Techniques mises en \u0153uvre :</li> <li>Pond\u00e9ration de la fonction de perte : Calcul des poids inverses des fr\u00e9quences des classes pour <code>torch.nn.CrossEntropyLoss</code>.</li> <li>Sampler pond\u00e9r\u00e9 : Optionnellement, utilisation de <code>torch.utils.data.WeightedRandomSampler</code> pour \u00e9quilibrer les classes lors de l'entra\u00eenement.</li> </ul>"},{"location":"pipeline/01_preparation/#4-modelisation","title":"4. \ud83e\udde0 Mod\u00e9lisation","text":"<ul> <li>Architecture personnalis\u00e9e : Convolutional Neural Network (CNN) d\u00e9fini dans <code>models/classifier.py</code>.</li> <li>Mod\u00e8les pr\u00e9-entra\u00een\u00e9s : Int\u00e9gration de mod\u00e8les tels que <code>ResNet18</code> via <code>torchvision.models</code> pour le transfert d'apprentissage.</li> <li>Fonction de perte : <code>torch.nn.CrossEntropyLoss</code> avec ou sans pond\u00e9ration.</li> <li>Optimiseur : <code>torch.optim.Adam</code> avec un taux d'apprentissage initial de 1e-4.</li> </ul>"},{"location":"pipeline/01_preparation/#5-entrainement","title":"5. \ud83c\udfcb\ufe0f Entra\u00eenement","text":"<ul> <li>Boucle d'entra\u00eenement : Impl\u00e9ment\u00e9e dans <code>training.py</code>, avec suivi de la perte et de la pr\u00e9cision.</li> <li>Sauvegarde du mod\u00e8le : Enregistrement des poids du mod\u00e8le apr\u00e8s chaque \u00e9poque si la performance s'am\u00e9liore.</li> <li>Visualisation : Courbes de perte et de pr\u00e9cision g\u00e9n\u00e9r\u00e9es \u00e0 l'aide de <code>matplotlib</code>.</li> </ul>"},{"location":"pipeline/01_preparation/#6-evaluation","title":"6. \ud83d\udcca \u00c9valuation","text":"<ul> <li>M\u00e9triques :</li> <li>Pr\u00e9cision globale.</li> <li>Matrice de confusion.</li> <li>Rapport de classification (pr\u00e9cision, rappel, F1-score).</li> <li>Explicabilit\u00e9 : Utilisation de <code>torchcam</code> pour g\u00e9n\u00e9rer des cartes de chaleur (Grad-CAM) illustrant les zones d'attention du mod\u00e8le.</li> </ul>"},{"location":"pipeline/01_preparation/#7-organisation-des-fichiers","title":"7. \ud83d\udcc1 Organisation des fichiers","text":"<pre><code>data/\n\u251c\u2500\u2500 raw/                # Images originales\n\u251c\u2500\u2500 processed/          # Donn\u00e9es apr\u00e8s s\u00e9paration\nmodels/\n\u251c\u2500\u2500 classifier.py       # D\u00e9finition du mod\u00e8le\n\u251c\u2500\u2500 utils.py            # Fonctions utilitaires\nnotebooks/\n\u251c\u2500\u2500 exploration.ipynb   # Analyse exploratoire\n\u251c\u2500\u2500 training.ipynb      # Entra\u00eenement du mod\u00e8le\nscripts/\n\u251c\u2500\u2500 split_data.py       # Script de s\u00e9paration des donn\u00e9es\n\u251c\u2500\u2500 train_model.py      # Script d'entra\u00eenement\n</code></pre>"}]}